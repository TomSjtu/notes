# 内核同步

只要有共享资源的地方，程序员在编写代码时就需要特别注意保护共享资源，防止并发访问时造成数据不一致的问题。多个线程并发访问共享数据是造成系统不稳定的一类隐患，而这类隐患往往难以跟踪和调试。要做到对共享资源的保护相当困难。早年，Linux还不支持SMP（对称多处理器），避免并发访问数据还比较容易。在单一处理器时，只有在中断发生的时候，或者程序明确请求重新调度（scheduler）的时候，数据才有可能被并发访问。于是在早期的单CPU架构下，简单的禁止中断即可保护共享资源。但是多处理器时代这一方法不再有效了，因为禁止中断只能禁止本地的中断，但是无法阻止其他CPU并发地访问数据。随着2.6内核版本的出现，Linux内核已经发展成抢占式内核。这意味着调度程序可以在任何时刻抢占正在执行的代码，重新调度其他的进程执行，这对数据的同步提出了更高的要求。具体请看[进程调度](sched.md)。

内核中并发执行的原因有：

- 中断——中断是异步的，几乎可以在任何时刻发生，也就有可能在任何时刻打断正在执行的代码。
- 软中断和tasklet——内核可以在任何时刻唤醒或调度软中断和tasklet。
- 抢占——内核是抢占性质的，正在执行的任务可能会被高优先级的任务抢占。
- 睡眠——在内核执行的进程可能睡眠，这会唤醒调度程序，从而调度另一个新的进程。
- SMP——多个CPU可以同时执行代码。

## 同步的概念

### 临界区

所谓临界区就是访问和操作共享数据的代码段。多个线程同时访问临界区代码是不安全的，因此临界区代码必须以原子地方式执行。考虑一个非常简单的情况。假设我们有一个全局变量i，操作仅仅是对其加1。

```C
i++;
```

如此简单的操作在CPU执行的时候需要三条汇编指令：

1. 从内存中读出变量i的值并放在一个寄存器内。
2. 将寄存器中的值+1。
3. 把i的值写回到内存。

实际上，在多线程并发的情况下，其他线程有可能在这三条指令间隙的任意时刻“插队”。这种概率虽然很小，但是计算机每秒运行上百万条指令，“插队”可能每过几秒就发生一次。假设有两个线程同时操作这个全局变量，若i的初始值为1，那么我们期望的最终结果应该是3。但是假如第二个线程在第一个线程执行最后一步之前就去内存中读取了i的值（此时i的值仍然是1），我们最后得到的i的值就是2而不是3，这与我们预期的值不符。

```C
#include <stdio.h>
#include <pthread.h>

int i = 0;

void *thread_func(void *arg)
{
    for(int j = 0 ;j < 1000000; j++)
    {
        i++;
    }

}

int main(int argc, char *argv[])
{

    pthread_t tid1, tid2;
    pthread_create(&tid1, NULL, thread_func, NULL);
    pthread_create(&tid2, NULL, thread_func, NULL);

    pthread_join(tid1, NULL);
    pthread_join(tid2, NULL);

    printf("i = %d\n", i);
    return 0;
}
```

以上是一段示例代码，在编译时请加上-lpthread，以链接正确的库。多次执行该程序后你会发现最终的结果是不确定的。

这是最简单的临界区例子，对于这种简单的竞争条件，我们不需要用到复杂的锁机制，因为锁对于CPU的性能有很大的影响。多数处理器都提供了指令来原子地读、写变量。我们称之为*原子指令*。使用原子指令可以解决一些简单的并发问题。两条原子指令不可能交错执行，因为处理器会从硬件上禁止这种可能性。

### 加锁

当共享资源是一个复杂的数据结构，而不是简单的i++时，原子指令就无能为力了。此时我们必须引入*锁*机制来保护共享资源的访问。同一时刻，我们只允许有一个线程持有锁，其他线程的访问必须等待第一个线程释放锁之后才能进行。锁有多种多样的形式，锁的粒度也各不相同。Linux内核提供了多种不同的锁机制，他们之间的主要区别在于：当锁被其他线程持有而不可用时的表现形式——有一些锁会在原地等待，而有一些锁会直接睡眠。锁没有优劣之分，在不同场景下用不同的锁是程序员必备的技能。

当一个锁正在被占用时，有其他线程试图获得该锁，我们称之为*锁的争用*。由于锁是让程序以串行的方式对资源进行访问，被长时间持有的锁无疑会降低系统的性能。于是加锁粒度就显得尤为重要。如果是一段加锁的代码被频繁的调用，这往往会成为系统性能的瓶颈。在一些大型机器上可能表现不是那么明显，但是在一些小型机器上，过粗的锁的粒度会严重拖累系统的性能。

### 死锁

死锁是编写同步代码时经常会遇到的问题，两个或多个线程因为争夺资源而无法继续执行，因为每个线程都在等待另一个线程释放锁或资源。如果没有外力干涉，这些线程将永远处于等待状态。

一个最简单的死锁例子就是自死锁：如果一个线程试图去获得一个自己已经持有的锁，那么它将永远等待下去。
另一个常见的例子叫ABBA死锁：线程1持有锁A，线程2持有锁B，线程1试图去获得锁B，而线程2试图去获得锁A，由于每个线程都在等待另一个线程释放锁，但是谁都不想释放自己的锁，于是就造成了死锁。预防死锁的发生非常重要，虽然你不知道自己的代码会不会发生死锁，但是遵循一些简单的规则对于避免死锁大有帮助：

- 按顺序加锁。使用多个锁时必须保证以相同的顺序获取锁，否则就有可能造成ABBA死锁。
- 防止*饥饿*。
- 不要重复请求同一个锁。
- 设计越简单越好。

## 同步的方法

### 原子操作

原子操作可以保证指令以不可分割的形式执行————执行过程不可被打断。内核提供了两组原子操作接口————一组针对整数，一组针对单独的位。在Linux支持的所有体系结构上都实现了这两组接口。注意：在不同体系结构上实现的方式是不同的，但是接口都是统一的。

有的时候我们会要求某些指令按照特定的顺序执行，这被称为顺序性，以屏障（barrier）指令来实现。

1.原子整数操作

针对整数的原子操作使用一个特殊的atomic_t类型的数据。它的定义在<linux/types.h\>中：

```C
typedef struct{
    volatile int counter;
}atomic_t;
```

使用原子整数操作的声明在<asm/atomic.h\>中定义。有些体系结构会提供一些额外的原子操作，但是内核的接口在所有体系结构上都实现了。

一些简单的操作比如：

```C
atomic_t v;   //定义v
atomic_t u = ATOMIC_INIT(0); //定义u并初始化为0
atomic_set(&v, 4);          //设置v的值为4
atomic_add(2, &v);          //将v的值增加2
int w = atomic_read(&v);    //将原子变量v转变为int变量
```

原子操作的接口非常简单易读，没有必要单独去记，用到什么就学什么。

原子操作通常是内联函数，且是用内嵌汇编指令来实现的。ARM体系请参考：[ARM GCC Inline Assembler](http://www.ethernut.de/en/documents/arm-inline-asm.html)。

atomic64_t类型是64位的原子变量，其功能和32位一致，函数接口以atomic64前缀命名。

```C
typedef struct {
    volatile long counter;
}atomic64_t;
```

2.原子位操作

atomic_t类型对整数算术来讲比较有用。但是当需要以原子形式来操作单个的位时，这种类型就无法派上用场了。Linux内核提供了一组对位的原子操作。

原子位的操作非常快，只要硬件底层硬件支持，这种操作可以使用单个机器指令来执行。这些函数与体系结构相关，定义在<asm/bitops.h\>中。即使是在SMP计算机上，这些函数依旧可以确保是原子的。原子位的参数是一个位号+指针。可用的操作如下：

```C
void set_bit(nr, void *addr);     //设置addr指向的第nr位
void clear_bit(nr, void *addr);   //清除addr指向的第nr位
void change_bit(nr, void *addr);  //切换addr指向的第nr位
test_bit(nr, void *addr);         //返回指定位的当前值
```

### 自旋锁

原子操作只能针对一些简单的数据结构进行保护，现实情况里，一个临界区里甚至有多个函数。比如我们有这样一个情况：从某个函数中读取某个struct类型的数据，然后改变其中某个成员的值，最后再把更新的值赋给另一个函数调用。整个执行过程必须是不可分割的，在数据更新完毕前，绝对不允许任何其他的代码读取这些数据。显然，我们不可能要求每个体系都支持如此复杂的操作，此时就需要用到更复杂的同步方法——锁来提供保护。

Linux内核中最常见的锁是自旋锁（spin lock）。自旋锁只能同时被一个线程持有，如果另一个线程试图获得一个已经被占用的自旋锁，那么该线程将会进入忙等待，直到锁可用。通俗的解释就是一扇门对应一把钥匙，要进入这扇门必须先检查门上有没有钥匙，如果没有就只能在外面等待直到里面的人出来。由于自旋会一直导致线程忙等待，白白占用了CPU资源而不会去做别的事情，因此特别浪费资源，所以自旋锁不应该被长时间占有。事实上，使用自旋锁时你必须保证临界区代码执行足够短，否则会严重影响系统的性能。

自旋锁的实现与体系结构密切相关，代码往往通过汇编实现。其定义在<asm/spinlock.h\>中，实际的接口定义在<linux/spinlock.h\>。自旋锁的基本使用如下：

```C
DEFINE_SPINLOCK(sp_lock);
spin_lock(&sp_lock);
/*临界区代码*/
spin_unlock(&sp_lock);
```

在单处理器上，如果禁止内核抢占，那么自旋锁不会被编译进内核。

自旋锁可以使用在中断处理程序中，获取锁之前，必须要禁止本地中断，否则中断处理程序会打断当前持有锁的代码，有可能去争用这个已经被持有的锁。这会导致死锁。注意，要关闭的只是当前处理器的中断，其他处理器的中断处理程序自旋并不会妨碍当前处理器释放锁。

内核提供了禁止中断同时请求锁的接口，方法如下：

```C
DEFINE_SPINLOCK(sp_lock);
unsigned long flags;
spin_lock_irqsave(&sp_lock, flags);
spin_unlock_irqrestore(&sp_lock, flags);
```

函数*spin_lock_irqsave()*保存中断状态，并禁止本地中断，然后再去获取锁。反过来*spin_unlock_irqrestore()*解锁，并让中断恢复到加锁前的状态。所以即便是加锁前中断已经被禁止了，代码也不会错误地激活中断，而是让中断保持禁止状态。

如果你能确定中断在加锁前是激活的，那么可以配对使用*spin_lock_irq()*和*spin_unlock_irq()*，从而在解锁时直接激活中断。但是内核的庞大性往往让人很难搞清楚中断在当前执行代码前是否处于激活状态，所以该方法并不提倡。

由于中断下半部可以抢占进程上下文的代码，因此加锁的同时还需要禁止下半部执行。函数*spin_lock_bh()*可以做到这一点。同样，中断处理程序可以抢占下半部，因此如果下半部有需要和中断处理程序共享的数据时，也必须禁止中断。

中断处理是另一个话题，请参考[中断及下半部](interrupt.md)。

### 读/写自旋锁

有时，锁的用途可以明确地分为读和写两个场景，尤其是那些需要大量读操作，而写操作很少的情况时，引入读写锁可以很大地改善系统的性能。读写锁的基本逻辑是：读模式是共享的，写模式是独占的。也就是说当进行写操作的时候，只能由单个任务进行。而进行读操作的时候，可以并发的执行而不用担心安全问题。读/写锁的基本方法如下：

```C
DEFINE_RWLOCK(rw_lock);
//读操作
read_lock(&rw_lock);
read_unlock(&rw_lock);
//写操作
write_lock(&rw_lock);
write_unlock(&rw_lock);
```

通常，读写操作应处于完全分割开的代码分支中，如果读写操作不能清晰地辨别，不要使用读写锁，否则可能会导致死锁。例如在执行读操作代码时，也加入了写操作。

在中断处理程序中，如果只有读操作，可以简单地使用*read_lock()*来保护读操作，而不需要禁止中断了。但是，写操作的中断必须禁止，否则就会造成死锁。因为写操作需要等待读操作释放锁，而读操作需要等待写操作的中断处理程序返回。

在使用读写锁的时候需要注意，当读锁被持有时，写锁只能等待。然而读锁却可以继续成功地占用锁。这会造成写锁*饥饿*现象。

如果加锁时间很长或者代码在持有锁时有可能睡眠，那么最好使用信号量来处理。

### 信号量

Linux中的信号量是一种睡眠锁。当有一个任务试图获得一个已经被占用的信号量时，该任务会加入等待队列，然后睡眠。由于释放了资源处理器可以去执行其他的代码。当持有的信号量被释放时，处于等待队列中的那个任务会被唤醒，并获得该信号量。

实际上，Linux提供两种信号量：

- 内核信号量，由内核态使用
- System V IPC信号量，由用户态使用

由于信号量会睡眠，因此有以下结论：

- 信号量适用于锁会被长时间占有的场景。
- 信号量只能在进程上下文中使用，因为中断上下文禁止睡眠。
- 多个进程试图获得信号量不会死锁。
- 如果已经占用了信号量，不能再使用自旋锁，因为自旋锁禁止睡眠。

信号量相比自旋锁有一个特殊的地方，就是它内部维护了一个count值，该count值等同于同一时间能够持有信号量的数量。如果这个值是1，那么信号量又被称为互斥信号量。信号量支持两个操作：down()操作通过对信号量计数减1来获得它，而up()操作加1来释放它。

信号量是与体系结构相关的，定义在<asm/semaphore.h\>中。创建方法如下：

```C
struct semaphore name;
sema_init(&name, count);
```

函数*down_interruptible()*试图获取指定的信号量，如果不可用，则将进程设置为TASK_INTERRUPTIBLE。这种进程状态意味着任务可以被信号唤醒。使用*down_trylock()*函数，在信号量已经被占用时，立即返回而不是让进程睡眠。

### 互斥体

在多数情况下，信号量只是作为一个计数为1的允许睡眠的自旋锁存在。为了找到一个更简单且可以睡眠的锁，开发者们引入了互斥体（mutex）。其行为和计数为1的信号量类似，但是操作的接口更简单，实现也更高效。基本适用方法如下：

```C
DEFINE_MUTEX(mutex);
mutex_init(&mutex);
mutex_lock(&mutex);
mutex_unlock(&mutex);
```

mutex的简介与高效源于相比使用信号量更多的受限性：

- 任何时刻只能有一个任务持有mutex。
- 必须由上锁者解锁——这意味着你不能在一个线程上锁，而在另一个线程解锁。
- 递归地上锁和解锁时不被允许的。
- 当持有一个mutex时，进程不能退出。
- mutex不能在中断或者下半部中使用。

| 需求        | 建议的加锁方式|
| ----------- | ----------- |
| 低开销加锁   |  优先使用自旋锁 |
| 短期加锁     | 优先使用自旋锁  |
| 长期加锁     | 优先使用互斥体  |
| 中断上下文加锁 | 使用自旋锁    |
| 持有锁需要睡眠 | 使用互斥体    |

### 完成变量

如果在内核中一个任务需要发送信号通知另一个任务发生了某种特定事件，此时可以用完成变量（completion variable）。当某个任务完成工作后，会使用完成变量去唤醒正在等待的任务。

完成变量由结构体completion表示，定义在<linux/completion.h\>中。其创建方法如下：

```C
DECLARE_COMPLETION(comp);
```

或者使用*init_completion()*动态创建。需要等待的任务调用*wait_for_completion()*来等待特定事件。当事件发生后，产生事件的任务调用*complete()*来发送信号唤醒正在等待的任务。

### RCU机制

读取-复制-更新（read-copy-update）是一种高级互斥机制，一般用不到但是我们对这个概念得有一个基本的了解。RCU机制主要针对读取经常发生、但是写入很少的情况。在需要修改数据时，写入线程首先复制一份，然后修改副本。其他线程在读取数据时，仍然指向原始的共享数据地址，这样就可以保证在写操作发生前，其他线程仍然可以读取到一致的数据。直到更新线程完成了数据的修改，并通过特定的API将更新后的数据指针赋值回原来的共享数据位置，这个过程称为“更新完成”。内存屏障指令用于保证只有在数据结构被修改之后，已更新的指针才对其他CPU可见。读取端的代码必须放置于*rcu_read_lock()*和*rcu_read_unlock()*之间。

使用RCU技术的难点在于：写入端修改指针时不能立刻释放数据结构的旧指针，因为还有其他的读取端在使用。只有当所有的读取端执行完宏*rcu_read_unlcok()*之后，才可以释放旧指针。写入端调用函数*call_rcu()*来释放旧指针。

### 禁止抢占

Linux是抢占式内核，其主要特点是：一个在内核态运行的进程，可能在执行内核态函数期间被另外一个进程抢占。在进程A执行异常处理程序时（次吃位于内核态），一个更有优先级的进程B变为可执行状态。如果内核是可抢占的，就会发生强制性任务切换，让B取代A。再比如，一个进程已经用完了它的时间片配额，抢占式内核会立刻让另一个进程取代它。

内核使用*thread_info*中的*preempt_count*字段表示抢占计数。当这个值大于0时，就禁止内核抢占。它在以下任何一种情况发生时，取值都大于0：

1. 内核正在执行中断服务程序。
2. 可延迟函数被禁止（当内核正在执行软中断或tasklet）。
3. 显示设置抢占计数器为正数。

| 宏          | 说明         |
| ----------- | ----------- |
| preempt_count() | 返回抢占计数值 |
| preempt_disable() | 使抢占计数+1|
| preempt_enable() | 使抢占计数-1，并检查TIF_NEED_RESCHED标志|
| preempt_enable_no_resched() | 使抢占计数-1 |

上面第三个宏需要说明一下。*preempt_enable()*宏首先递减抢占计数器，并且检查TIF_NEED_RESCHED标志是否被设置。当这个标志为1时表示需要执行调度程序。于是我们还会调用*preempt_schedule()*来调用*schedule()*选择另外一个进程运行。

### 顺序与屏障

为什么需要顺序和屏障指令？

- 防止编译器优化导致的重排：现代编译器会进行各种优化以提高程序的执行效率，包括指令重排。在不考虑内存操作顺序的情况下，编译器可能会改变指令的执行顺序，这可能导致程序的行为与预期不符。通过使用顺序和屏障指令，可以限制编译器对某些关键代码段的优化。

- 保证并发操作的一致性：在多核处理器和多线程编程中，为了提高性能，操作系统的调度器可能会在不同的处理器核心上并行执行多个线程。为了保持一致性，需要确保所有核心上的内存操作都按照程序指定的顺序执行。

- 解决CPU缓存一致性问题：CPU缓存是处理器速度的关键部分，但它的存在也带来了缓存一致性的问题。当一个CPU核心写入数据，而这个数据又被另一个核心的缓存所缓存时，没有屏障的话，另一个核心可能会读取到旧的数据版本。内存屏障能够确保所有核心看到内存操作的最终一致性。

Linux中的内存屏障指令：

| 宏 | 说明 |
| ---- | ---- |
| mb() | 适用于MP和UP的内存屏障 |
| rmb() | 适用于MP和UP的读内存屏障 |
| wmb() | 适用于MP和UP的写内存屏障 |
| smp_mb() | 仅适用于MP的内存屏障 |
| smp_rmb() | 仅适用于MP的读内存屏障 |
| smp_wmb() | 仅适用于MP的写内存屏障 |

此类指令与体系结构密切相关，请参考[ARM内存屏障指令](../../arm/barrier.md)。
